{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usmDrBnO2bpl",
        "outputId": "97e65b6a-6285-4ad7-fff8-66eb68929086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers requests pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIdjOKj07m6-",
        "outputId": "b394b3ea-b68e-4aaa-9c6e-f05f1824fec9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# dataset path\n",
        "dataset_path = '/content/drive/MyDrive/fake-news-detection/Dataset/'\n",
        "\n",
        "# Load the TSV files\n",
        "train_df = pd.read_csv(os.path.join(dataset_path, 'multimodal_train.tsv'), sep='\\t')\n",
        "validate_df = pd.read_csv(os.path.join(dataset_path, 'multimodal_validate.tsv'), sep='\\t')\n",
        "test_df = pd.read_csv(os.path.join(dataset_path, 'multimodal_test_public.tsv'), sep='\\t')\n",
        "\n",
        "print(\"Training set shape:\", train_df.shape)\n",
        "print(\"\\nValidation set shape:\", validate_df.shape)\n",
        "print(\"\\nTest set shape:\", test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeYFrhXq2dis",
        "outputId": "1886abf0-ed3a-4ef2-a596-76d9ac72bb56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (564000, 16)\n",
            "\n",
            "Validation set shape: (59342, 16)\n",
            "\n",
            "Test set shape: (59319, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Configuration\n",
        "TARGET_TRAIN_SIZE = 10000\n",
        "TARGET_VAL_SIZE = 2000\n",
        "\n",
        "def check_url(row):\n",
        "    \"\"\"\n",
        "    Returns the row if the URL is valid (Status 200), otherwise None.\n",
        "    \"\"\"\n",
        "    url = row['image_url']\n",
        "    try:\n",
        "        response = requests.head(url, timeout=3, allow_redirects=True)\n",
        "        if response.status_code == 200:\n",
        "            return row\n",
        "    except:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def get_clean_samples(df, target_size):\n",
        "    \"\"\"\n",
        "    Iterates through the dataframe until it finds 'target_size' valid images.\n",
        "    \"\"\"\n",
        "    clean_rows = []\n",
        "\n",
        "    # We shuffle first to get a random distribution\n",
        "    shuffled_df = df.sample(frac=1, random_state=42)\n",
        "\n",
        "    print(f\"Scanning for {target_size} valid images...\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=20) as executor:\n",
        "\n",
        "        futures = []\n",
        "        for i in range(len(shuffled_df)):\n",
        "            futures.append(executor.submit(check_url, shuffled_df.iloc[i]))\n",
        "            if len(futures) >= target_size * 2:\n",
        "                break\n",
        "\n",
        "        for future in tqdm(futures, total=len(futures)):\n",
        "            result = future.result()\n",
        "            if result is not None:\n",
        "                clean_rows.append(result)\n",
        "                if len(clean_rows) >= target_size:\n",
        "                    break\n",
        "\n",
        "    return pd.DataFrame(clean_rows)\n",
        "\n",
        "print(\"Cleaning Training Set...\")\n",
        "df_train_clean = get_clean_samples(train_df, TARGET_TRAIN_SIZE)\n",
        "print(f\"Secured {len(df_train_clean)} valid training images.\")\n",
        "\n",
        "print(\"Cleaning Validation Set...\")\n",
        "df_val_clean = get_clean_samples(validate_df, TARGET_VAL_SIZE)\n",
        "print(f\"Secured {len(df_val_clean)} valid validation images.\")\n",
        "\n",
        "print(\"Cleaning Test Set...\")\n",
        "df_test_clean = get_clean_samples(test_df, TARGET_VAL_SIZE)\n",
        "print(f\"Secured {len(df_test_clean)} valid test images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSzeP10c9Sb9",
        "outputId": "f662d04b-7b19-4333-ff1b-d617c3c58784"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning Training Set...\n",
            "Scanning for 10000 valid images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [01:30<00:00, 220.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secured 6765 valid training images.\n",
            "Cleaning Validation Set...\n",
            "Scanning for 2000 valid images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4000/4000 [00:17<00:00, 230.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secured 1134 valid validation images.\n",
            "Cleaning Test Set...\n",
            "Scanning for 2000 valid images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4000/4000 [00:14<00:00, 277.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secured 1087 valid test images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import CLIPModel, CLIPProcessor\n",
        "\n",
        "class MultimodalCLIPClassifier(nn.Module):\n",
        "    def __init__(self, num_labels=6):\n",
        "        super(MultimodalCLIPClassifier, self).__init__()\n",
        "        self.clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "        for param in self.clip.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.classifier = nn.Linear(1280, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, pixel_values, attention_mask):\n",
        "        outputs = self.clip(\n",
        "            input_ids=input_ids,\n",
        "            pixel_values=pixel_values,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        text_features = outputs.text_model_output.pooler_output\n",
        "        image_features = outputs.vision_model_output.pooler_output\n",
        "\n",
        "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
        "\n",
        "        logits = self.classifier(combined_features)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "bfVTthVQ2ij8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FakedditMultimodalDataset(Dataset):\n",
        "    def __init__(self, df, processor):\n",
        "        self.data = df.reset_index(drop=True)\n",
        "        self.processor = processor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        text = str(self.data.iloc[idx]['clean_title'])\n",
        "        label = self.data.iloc[idx]['6_way_label']\n",
        "        img_url = self.data.iloc[idx]['image_url']\n",
        "\n",
        "        try:\n",
        "            response = requests.get(img_url, timeout=5)\n",
        "            image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        except:\n",
        "\n",
        "            image = Image.new('RGB', (224, 224), color='black')\n",
        "\n",
        "        inputs = self.processor(\n",
        "            text=text,\n",
        "            images=image,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=77\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(0),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
        "            'pixel_values': inputs['pixel_values'].squeeze(0),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "DY_Ws8i27y_R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import CLIPProcessor\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "train_dataset = FakedditMultimodalDataset(df_train_clean, processor)\n",
        "val_dataset = FakedditMultimodalDataset(df_val_clean, processor)\n",
        "test_dataset = FakedditMultimodalDataset(df_test_clean, processor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "model = MultimodalCLIPClassifier(num_labels=6).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n"
      ],
      "metadata": {
        "id": "CGv-T5xcJgzL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_multimodal_epoch(model, optimizer, criterion, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Training\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        pixel_values = batch['pixel_values'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(input_ids, pixel_values, attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct += (logits.argmax(1) == labels).sum().item()\n",
        "\n",
        "    return total_loss / len(loader), correct / len(loader.dataset)\n"
      ],
      "metadata": {
        "id": "x1IGmlf_72_v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_multimodal_epoch(model, criterion, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Validation\"):\n",
        "\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            pixel_values = batch['pixel_values'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits = model(input_ids, pixel_values, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (logits.argmax(1) == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    avg_acc = correct / len(loader.dataset)\n",
        "\n",
        "    return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "WUAtHlEl7_h0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 5\n",
        "best_val_acc = 0\n",
        "\n",
        "print(\"Starting Training...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\n=== Epoch {epoch + 1}/{epochs} ===\")\n",
        "\n",
        "    # 1. Train\n",
        "    train_loss, train_acc = train_multimodal_epoch(model, optimizer, criterion, train_loader)\n",
        "\n",
        "    # 2. Validate\n",
        "    val_loss, val_acc = eval_multimodal_epoch(model, criterion, val_loader)\n",
        "\n",
        "    # 3. Report\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
        "\n",
        "    # 4. Save Checkpoint (if improved)\n",
        "    if val_acc > best_val_acc:\n",
        "        print(f\"--> Accuracy improved from {best_val_acc:.4f} to {val_acc:.4f}. Saving model...\")\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_multimodal_clip.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keswbnIAJRgq",
        "outputId": "2414c55a-8f80-494b-cc72-ffde1ede2aeb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training...\n",
            "\n",
            "=== Epoch 1/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 846/846 [05:45<00:00,  2.45it/s]\n",
            "Validation: 100%|██████████| 142/142 [01:01<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6932 | Train Acc: 0.7484\n",
            "Val Loss:   0.4915 | Val Acc:   0.8192\n",
            "--> Accuracy improved from 0.0000 to 0.8192. Saving model...\n",
            "\n",
            "=== Epoch 2/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 846/846 [05:24<00:00,  2.61it/s]\n",
            "Validation: 100%|██████████| 142/142 [01:01<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4513 | Train Acc: 0.8389\n",
            "Val Loss:   0.4406 | Val Acc:   0.8342\n",
            "--> Accuracy improved from 0.8192 to 0.8342. Saving model...\n",
            "\n",
            "=== Epoch 3/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 846/846 [05:21<00:00,  2.63it/s]\n",
            "Validation: 100%|██████████| 142/142 [01:00<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3878 | Train Acc: 0.8594\n",
            "Val Loss:   0.4135 | Val Acc:   0.8413\n",
            "--> Accuracy improved from 0.8342 to 0.8413. Saving model...\n",
            "\n",
            "=== Epoch 4/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 846/846 [05:29<00:00,  2.57it/s]\n",
            "Validation: 100%|██████████| 142/142 [01:02<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3470 | Train Acc: 0.8715\n",
            "Val Loss:   0.4017 | Val Acc:   0.8439\n",
            "--> Accuracy improved from 0.8413 to 0.8439. Saving model...\n",
            "\n",
            "=== Epoch 5/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 846/846 [05:30<00:00,  2.56it/s]\n",
            "Validation: 100%|██████████| 142/142 [01:03<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3180 | Train Acc: 0.8865\n",
            "Val Loss:   0.4006 | Val Acc:   0.8510\n",
            "--> Accuracy improved from 0.8439 to 0.8510. Saving model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = MultimodalCLIPClassifier().to(device)\n",
        "best_model.load_state_dict(torch.load('best_multimodal_clip.pt'))\n",
        "\n",
        "test_loss, test_acc = eval_multimodal_epoch(best_model, criterion, test_loader)\n",
        "\n",
        "print(\"=\"*30)\n",
        "print(f\"FINAL TEST RESULTS\")\n",
        "print(\"=\"*30)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss:     {test_loss:.4f}\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "id": "iALaD0IdJrRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aabaf24-916e-4860-fd6f-57a615c8f1e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 136/136 [00:59<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "FINAL TEST RESULTS\n",
            "==============================\n",
            "Test Accuracy: 0.8464\n",
            "Test Loss:     0.3884\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XWQ-KulWJ60k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def get_all_preds_clip(model, loader):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Total batches to process: {len(loader)}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            pixel_values = batch['pixel_values'].to(device)\n",
        "\n",
        "            labels = batch.get('label', batch.get('labels')).to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                pixel_values=pixel_values\n",
        "            )\n",
        "\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "\n",
        "print(\"Generating predictions...\")\n",
        "preds, labels = get_all_preds_clip(model, val_loader)\n",
        "\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix (CLIP)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "ira_4nZ7B-Jl",
        "outputId": "82ad6d38-a807-4c0a-b3bb-bd3d370be3c2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating predictions...\n",
            "Total batches to process: 142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']\n",
        "\n",
        "print(\"-----------------------------------------------------------\")\n",
        "print(\"                CLASSIFICATION REPORT\")\n",
        "print(\"-----------------------------------------------------------\")\n",
        "\n",
        "report = classification_report(labels, preds, target_names=class_names, digits=4)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1vyyetnJ_Mh",
        "outputId": "1bf69ab6-3ca4-4011-ae92-12673e948992"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------\n",
            "                CLASSIFICATION REPORT\n",
            "-----------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0     0.8446    0.9225    0.8818       542\n",
            "     Class 1     0.9135    0.9314    0.9223       102\n",
            "     Class 2     0.8311    0.7789    0.8042       398\n",
            "     Class 3     0.6667    0.2727    0.3871        22\n",
            "     Class 4     0.9412    0.5714    0.7111        28\n",
            "     Class 5     0.9744    0.9048    0.9383        42\n",
            "\n",
            "    accuracy                         0.8510      1134\n",
            "   macro avg     0.8619    0.7303    0.7741      1134\n",
            "weighted avg     0.8498    0.8510    0.8465      1134\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EE7qeD2BVFSW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}